Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Bertola2015,
abstract = {The thermal response of a closed thermodynamic system perturbed by random fluctuations of the heat transfer rate through its boundary is studied by means of stochastic differential equations, in analogy with the mesoscopic thermodynamics approach. It is shown that the probability density of the thermodynamic beta (inverse temperature), which reflects the system randomisation due to the perturbation, can be significantly different from that of the perturbation itself.},
author = {Bertola, V. and Cafaro, E.},
doi = {10.1016/j.physleta.2015.10.026},
issn = {03759601},
journal = {Physics Letters, Section A: General, Atomic and Solid State Physics},
keywords = {Fokker-Planck equation,Random perturbations,Thermodynamic system},
month = {dec},
number = {47-48},
pages = {3035--3036},
publisher = {Elsevier B.V.},
title = {{Response of a thermodynamic system subject to stochastic thermal perturbations}},
volume = {379},
year = {2015}
}
@article{Sims2020,
abstract = {The notion of a physiological individuals has been developed and applied in the philosophy of biology to understand symbiosis, an understanding of which is key to theorising about the major transition in evolution from multi-organismality to multi-cellularity. The paper begins by asking what such symbiotic individuals can help to reveal about a possible transition in the evolution of cognition. Such a transition marks the movement from cooperating individual biological cognizers to a functionally integrated cognizing unit. Somewhere along the way, did such cognizing units simultaneously have cognizers as parts? Expanding upon the multiscale integration view of the Free Energy Principle, this paper develops an account of reciprocal integration, demonstrating how some coupled biological cognizing systems, when certain constraints are met, can result in a cognizing unit that is in ways greater than the sum of its cognizing parts. Symbiosis between V. Fischeri bacteria and the bobtail squid is used to provide an illustration this account. A novel manner of conceptualizing biological cognizers as gradient is then suggested. Lastly it is argued that the reason why the notion of ontologically nested cognizers may be unintuitive stems from the fact that our folk-psychology notion of what a cognizer is has been deeply influenced by our folk-biological manner of understanding biological individuals as units of reproduction.},
author = {Sims, Matthew},
doi = {10.1007/s11229-020-02876-w},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Sims2020{\_}Article{\_}HowToCountBiologicalMindsSymbi.pdf:pdf},
issn = {15730964},
journal = {Synthese},
keywords = {Active inference,Cognitive evolution,Emergence,Free energy principle,Multiscale integration,Nested Markov blankets,Physiological individuals,Symbiosis},
publisher = {Springer Netherlands},
title = {{How to count biological minds: symbiosis, the free energy principle, and reciprocal multiscale integration}},
url = {https://doi.org/10.1007/s11229-020-02876-w},
year = {2020}
}
@article{Bruineberg2018,
abstract = {In this paper, we argue for a theoretical separation of the free-energy principle from Helmholtzian accounts of the predictive brain. The free-energy principle is a theoretical framework capturing the imperative for biological self-organization in information-theoretic terms. The free-energy principle has typically been connected with a Bayesian theory of predictive coding, and the latter is often taken to support a Helmholtzian theory of perception as unconscious inference. If our interpretation is right, however, a Helmholtzian view of perception is incompatible with Bayesian predictive coding under the free-energy principle. We argue that the free energy principle and the ecological and enactive approach to mind and life make for a much happier marriage of ideas. We make our argument based on three points. First we argue that the free energy principle applies to the whole animal–environment system, and not only to the brain. Second, we show that active inference, as understood by the free-energy principle, is incompatible with unconscious inference understood as analagous to scientific hypothesis-testing, the main tenet of a Helmholtzian view of perception. Third, we argue that the notion of inference at work in Bayesian predictive coding under the free-energy principle is too weak to support a Helmholtzian theory of perception. Taken together these points imply that the free energy principle is best understood in ecological and enactive terms set out in this paper.},
author = {Bruineberg, Jelle and Kiverstein, Julian and Rietveld, Erik},
doi = {10.1007/s11229-016-1239-1},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Bruineberg2018{\_}Article{\_}TheAnticipatingBrainIsNotAScie.pdf:pdf},
issn = {15730964},
journal = {Synthese},
keywords = {Action-readiness,Active inference,Affordances,Enaction,Free-energy principle,Metastability,Predictive-coding,Skilled intentionality},
number = {6},
pages = {2417--2444},
publisher = {Springer Netherlands},
title = {{The anticipating brain is not a scientist: the free-energy principle from an ecological-enactive perspective}},
volume = {195},
year = {2018}
}
@article{Steffen2018,
abstract = {We explore the risk that self-reinforcing feedbacks could push the Earth System toward a planetary threshold that, if crossed, could prevent stabilization of the climate at intermediate temperature rises and cause continued warming on a “Hothouse Earth” pathway even as human emissions are reduced. Crossing the threshold would lead to a much higher global average temperature than any interglacial in the past 1.2 million years and to sea levels significantly higher than at any time in the Holocene. We examine the evidence that such a threshold might exist and where it might be. If the threshold is crossed, the resulting trajectory would likely cause serious disruptions to ecosystems, society, and economies. Collective human action is required to steer the Earth System away from a potential threshold and stabilize it in a habitable interglacial-like state. Such action entails stewardship of the entire Earth System—biosphere, climate, and societies—and could include decarbonization of the global economy, enhancement of biosphere carbon sinks, behavioral changes, technological innovations, new governance arrangements, and transformed social values.},
author = {Steffen, Will and Rockstr{\"{o}}m, Johan and Richardson, Katherine and Lenton, Timothy M. and Folke, Carl and Liverman, Diana and Summerhayes, Colin P. and Barnosky, Anthony D. and Cornell, Sarah E. and Crucifix, Michel and Donges, Jonathan F. and Fetzer, Ingo and Lade, Steven J. and Scheffer, Marten and Winkelmann, Ricarda and Schellnhuber, Hans Joachim},
doi = {10.1073/pnas.1810141115},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steffen et al. - 2018 - Trajectories of the Earth System in the Anthropocene.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Anthropocene,Biosphere feedbacks,Climate change,Earth system trajectories,Tipping elements},
number = {33},
pages = {8252--8259},
pmid = {30082409},
title = {{Trajectories of the Earth System in the Anthropocene}},
volume = {115},
year = {2018}
}
@article{Schwartenbeck2013,
abstract = {This paper reviews recent developments under the free energy principle that introduce a normative perspective on classical economic (utilitarian) decision-making based on (active) Bayesian inference. It has been suggested that the free energy principle precludes novelty and complexity, because it assumes that biological systems-like ourselves-try to minimize the long-term average of surprise to maintain their homeostasis. However, recent formulations show that minimizing surprise leads naturally to concepts such as exploration and novelty bonuses. In this approach, agents infer a policy that minimizes surprise by minimizing the difference (or relative entropy) between likely and desired outcomes, which involves both pursuing the goal-state that has the highest expected utility (often termed "exploitation") and visiting a number of different goal-states ("exploration"). Crucially, the opportunity to visit new states increases the value of the current state. Casting decision-making problems within a variational framework, therefore, predicts that our behavior is governed by both the entropy and expected utility of future states. This dissolves any dialectic between minimizing surprise and exploration or novelty seeking. {\textcopyright} 2013 Schwartenbeck, FitzGerald, Dolan and Friston.},
author = {Schwartenbeck, Philipp and FitzGerald, Thomas and Dolan, Raymond J and Friston, Karl},
doi = {10.3389/fpsyg.2013.00710},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwartenbeck et al. - 2013 - Exploration, novelty, surprise, and free energy minimization.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Active inference,Exploitation,Exploration,Free energy,Novelty,Reinforcement learning},
number = {OCT},
title = {{Exploration, novelty, surprise, and free energy minimization}},
url = {www.frontiersin.org},
volume = {4},
year = {2013}
}
@article{Crutzen2002,
author = {Crutzen, Paul J.},
doi = {10.1038/415023a},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Crutzen - 2002 - Geology of mankind.pdf:pdf},
issn = {00280836},
journal = {Nature},
number = {6867},
pages = {23},
pmid = {11780095},
title = {{Geology of mankind}},
volume = {415},
year = {2002}
}
@article{Millidge2020a,
abstract = {Active Inference (AIF) is an emerging framework in the brain sciences which suggests that biological agents act to minimise a variational bound on model evidence. Control-as-Inference (CAI) is a framework within reinforcement learning which casts decision making as a variational inference problem. While these frameworks both consider action selection through the lens of variational inference, their relationship remains unclear. Here, we provide a formal comparison between them and demonstrate that the primary difference arises from how value is incorporated into their respective generative models. In the context of this comparison, we highlight several ways in which these frameworks can inform one another.},
archivePrefix = {arXiv},
arxivId = {arXiv:2006.12964v1},
author = {Millidge, Beren and Seth, Anil K. and Tschantz, Alexander and Buckley, Christopher L.},
eprint = {arXiv:2006.12964v1},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Millidge{\_}2020{\_}ActInf{\_}control{\_}as{\_}inference.pdf:pdf},
journal = {arXiv},
title = {{on the Relationship of Active Inference and Control As Inference}},
year = {2020}
}
@article{Fletcher2009,
abstract = {Advances in cognitive neuroscience offer us new ways to understand the symptoms of mental illness by uniting basic neurochemical and neurophysiological observations with the conscious experiences that characterize these symptoms. Cognitive theories about the positive symptoms of schizophrenia - hallucinations and delusions - have tended to treat perception and belief formation as distinct processes. However, recent advances in computational neuroscience have led us to consider the unusual perceptual experiences of patients and their sometimes bizarre beliefs as part of the same core abnormality - a disturbance in error-dependent updating of inferences and beliefs about the world. We suggest that it is possible to understand these symptoms in terms of a disturbed hierarchical Bayesian framework, without recourse to separate considerations of experience and belief. {\textcopyright} 2009 Macmillan Publishers Limited. All rights reserved.},
author = {Fletcher, Paul C. and Frith, Chris D.},
doi = {10.1038/nrn2536},
issn = {1471003X},
journal = {Nature Reviews Neuroscience},
pmid = {19050712},
title = {{Perceiving is believing: A Bayesian approach to explaining the positive symptoms of schizophrenia}},
year = {2009}
}
@article{Hipolito2020,
abstract = {Wright and Bourke's compelling article rightly points out that existing models of embryogenesis fail to explain the mechanisms and functional significance of the dynamic connections among neurons. We pursue their account of Dynamic Logic by appealing to the Markov blanket formalism that underwrites the Free Energy Principle. We submit that this allows one to model embryogenesis as self-organisation in a dynamical system that minimises free-energy. The ensuing formalism may be extended to also explain the autonomous emergence of cognition, specifically in the brain, as a dynamic self-assembling process.},
archivePrefix = {arXiv},
arxivId = {2007.15205},
author = {Hip{\'{o}}lito, In{\^{e}}s and Ramstead, Maxwell and Constant, Axel and Friston, Karl J.},
doi = {10.1016/j.plrev.2020.08.001},
eprint = {2007.15205},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Hipolito{\_}2020{\_}CognitionAndComingAbout.pdf:pdf},
issn = {15710645},
journal = {arXiv},
keywords = {Embryogenesis,Free Energy Principle,Markov blankets,Self-organisation},
title = {{Cognition coming about: self-organisation and free-energy}},
year = {2020}
}
@article{Friston2003,
abstract = {In this paper we present an approach to the identification of nonlinear input-state-output systems. By using a bilinear approximation to the dynamics of interactions among states, the parameters of the implicit causal model reduce to three sets. These comprise (1) parameters that mediate the influence of extrinsic inputs on the states, (2) parameters that mediate intrinsic coupling among the states, and (3) [bilinear] parameters that allow the inputs to modulate that coupling. Identification proceeds in a Bayesian framework given known, deterministic inputs and the observed responses of the system. We developed this approach for the analysis of effective connectivity using experimentally designed inputs and fMRI responses. In this context, the coupling parameters correspond to effective connectivity and the bilinear parameters reflect the changes in connectivity induced by inputs. The ensuing framework allows one to characterise fMRI experiments, conceptually, as an experimental manipulation of integration among brain regions (by contextual or trial-free inputs, like time or attentional set) that is revealed using evoked responses (to perturbations or trial-bound inputs, like stimuli). As with previous analyses of effective connectivity, the focus is on experimentally induced changes in coupling (cf., psychophysiologic interactions). However, unlike previous approaches in neuroimaging, the causal model ascribes responses to designed deterministic inputs, as opposed to treating inputs as unknown and stochastic. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
author = {Friston, Karl and Harrison, Lee and Penny, W.},
doi = {10.1016/S1053-8119(03)00202-7},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2003{\_}DCM.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {Bilinear model,Effective connectivity,Functional neuroimaging,Hemodynamic response function,Nonlinear system identification,fMRI},
number = {4},
pages = {1273--1302},
pmid = {12948688},
title = {{Dynamic causal modelling}},
volume = {19},
year = {2003}
}
@article{Levin,
abstract = {Understanding how organisms establish their form during embryogenesis and regeneration represents a major knowledge gap in biological pattern formation. It has been recently suggested that morphogenesis could be understood in terms of cellular information processing and the ability of cell groups to model shape. Here, we offer a proof of principle that self-assembly is an emergent property of cells that share a common (genetic and epigenetic) model of organismal form. This behaviour is formulated in terms of variational free-energy minimization-of the sort that has been used to explain action and perception in neuroscience. In brief, casting the minimization of thermo-dynamic free energy in terms of variational free energy allows one to interpret (the dynamics of) a system as inferring the causes of its inputs-and acting to resolve uncertainty about those causes. This novel perspective on the coordination of migration and differentiation of cells suggests an interpretation of genetic codes as parametrizing a generative model-predicting the signals sensed by cells in the target morphology-and epigenetic processes as the subsequent inversion of that model. This theoretical formulation may complement bottom-up strategies-that currently focus on molecular pathways-with (constructivist) top-down approaches that have proved themselves in neuroscience and cybernetics.},
author = {Levin, Michael and Friston, Karl and Sengupta, Biswa and Pezzulo, Giovanni},
doi = {10.1098/rsif.2014.1383},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Levin et al. - Unknown - Knowing one's place a free-energy approach to pattern regulation.pdf:pdf},
keywords = {Subject Areas: biocomplexity,biomathematics Keywords: active inference,free energy,morphogenesis,pattern formation,random attractor,self-assembly,systems biology},
title = {{Knowing one's place: a free-energy approach to pattern regulation}},
url = {http://dx.doi.org/10.1098/rsif.2014.1383},
year = {2015}
}
@article{Bogacz2017b,
abstract = {This paper provides an easy to follow tutorial on the free-energy framework for modelling perception developed by Friston, which extends the predictive coding model of Rao and Ballard. These models assume that the sensory cortex infers the most likely values of attributes or features of sensory stimuli from the noisy inputs encoding the stimuli. Remarkably, these models describe how this inference could be implemented in a network of very simple computational elements, suggesting that this inference could be performed by biological networks of neurons. Furthermore, learning about the parameters describing the features and their uncertainty is implemented in these models by simple rules of synaptic plasticity based on Hebbian learning. This tutorial introduces the free-energy framework using very simple examples, and provides step-by-step derivations of the model. It also discusses in more detail how the model could be implemented in biological neural circuits. In particular, it presents an extended version of the model in which the neurons only sum their inputs, and synaptic plasticity only depends on activity of pre-synaptic and post-synaptic neurons.},
author = {Bogacz, Rafal},
doi = {10.1016/j.jmp.2015.11.003},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/A{\_}tutorial{\_}on{\_}the{\_}free-energy{\_}framework{\_}for{\_}modell.pdf:pdf;:home/esther/Desktop/bachelor/papers/potentially nteresting/Bogacz{\_}2018{\_}Tutorial{\_}FEModelling.pdf:pdf},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
number = {2005},
pages = {198--211},
pmid = {28298703},
publisher = {Elsevier Inc.},
title = {{A tutorial on the free-energy framework for modelling perception and learning}},
url = {http://dx.doi.org/10.1016/j.jmp.2015.11.003},
volume = {76},
year = {2017}
}
@article{Salman2018a,
abstract = {Recent literature in the robot learning community has focused on learning robot skills that abstract out lower-level details of robot control, such as Dynamic Movement Primitives (DMPs), the options framework in hierarchical RL, and subtask policies. To fully leverage the efficacy of these macro actions, it is necessary to then sequence these primitives to achieve a given task. Our objective is to jointly learn a set of robot skills and a sequence of these learnt skills to accomplish a given task. We consider the task of navigating a robot across various environments using visual input, maximizing the distance traveled through the environment while avoiding static obstacles. Traditional planning methods to solve this problem rely on hand-crafted state representations and heuristics for planning, and often fail to generalize. In contrast, deep neural networks have proved to be powerful function approximators, successfully modeling complex control policies. In addition, the ability of such networks to learn good representations of high-dimensional sensory inputs makes them a valuable tool when dealing with visual inputs. In this project, we explore the capability of deep neural networks to learn and sequence robot skills for navigation, directly using visual input.},
archivePrefix = {arXiv},
arxivId = {1803.01446},
author = {Salman, Hadi and Grover, Jaskaran and Shankar, Tanmay},
doi = {10.1162/NECO},
eprint = {1803.01446},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2017a{\_}ActInf{\_}ProcessTheory.pdf:pdf;:home/esther/Desktop/bachelor/papers/Schw{\"{o}}bel{\_}2020{\_}ActInf{\_}BeliefProp{\_}BetheApprox.pdf:pdf},
pages = {2709--2733},
title = {{Hierarchical Reinforcement Learning for Sequencing Behaviors}},
url = {http://arxiv.org/abs/1803.01446},
volume = {2733},
year = {2018}
}
@article{Buckley2017,
abstract = {The ‘free energy principle' (FEP) has been suggested to provide a unified theory of the brain, integrating data and theory relating to action, perception, and learning. The theory and implementation of the FEP combines insights from Helmholtzian ‘perception as inference', machine learning theory, and statistical thermodynamics. Here, we provide a detailed mathematical evaluation of a suggested biologically plausible implementation of the FEP that has been widely used to develop the theory. Our objectives are (i) to describe within a single article the mathematical structure of this implementation of the FEP; (ii) provide a simple but complete agent-based model utilising the FEP and (iii) to disclose the assumption structure of this implementation of the FEP to help elucidate its significance for the brain sciences.},
archivePrefix = {arXiv},
arxivId = {1705.09156},
author = {Buckley, Christopher L. and Kim, Chang Sub and McGregor, Simon and Seth, Anil K.},
doi = {10.1016/j.jmp.2017.09.004},
eprint = {1705.09156},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/CBuckley{\_}2017{\_}FEP{\_}math{\_}review.pdf:pdf},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
keywords = {Action,Agent-based model,Bayesian brain,Free energy principle,Inference,Perception},
pages = {55--79},
publisher = {Elsevier Inc.},
title = {{The free energy principle for action and perception: A mathematical review}},
url = {http://dx.doi.org/10.1016/j.jmp.2017.09.004},
volume = {81},
year = {2017}
}
@article{Tschantz2019,
abstract = {In reinforcement learning (RL), agents often operate in partially observed and uncertain environments. Model-based RL suggests that this is best achieved by learning and exploiting a probabilistic model of the world. 'Active inference' is an emerging normative framework in cognitive and computational neuroscience that offers a unifying account of how biological agents achieve this. On this framework, inference, learning and action emerge from a single imperative to maximize the Bayesian evidence for a niched model of the world. However, implementations of this process have thus far been restricted to low-dimensional and idealized situations. Here, we present a working implementation of active inference that applies to high-dimensional tasks, with proof-of-principle results demonstrating efficient exploration and an order of magnitude increase in sample efficiency over strong model-free baselines. Our results demonstrate the feasibility of applying active inference at scale and highlight the operational homologies between active inference and current model-based approaches to RL.},
archivePrefix = {arXiv},
arxivId = {1911.10601},
author = {Tschantz, Alexander and Baltieri, Manuel and Seth, Anil K. and Buckley, Christopher L.},
eprint = {1911.10601},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Tschantz{\_}2019{\_}ScalingActInf.pdf:pdf},
issn = {23318422},
journal = {arXiv},
month = {nov},
pages = {1--13},
publisher = {arXiv},
title = {{Scaling active inference}},
year = {2019}
}
@misc{Schwobel2018,
abstract = {When modeling goal-directed behavior in the presence of various sources of uncertainty, planning can be described as an inference process. A solution to the problem of planning as inference was previously proposed in the active inference framework in the form of an approximate inference scheme based on variational free energy. However, this approximate scheme was based on the mean-field approximation, which assumes statistical independence of hidden variables and is known to show overconfidence and may converge to local minima of the free energy. To better capture the spatiotemporal properties of an environment, we reformulated the approximate inference process using the so-called Bethe approximation. Importantly, the Bethe approximation allows for representation of pairwise statistical dependencies. Under these assumptions, the minimizer of the variational free energy corresponds to the belief propagation algorithm, commonly used in machine learning. To illustrate the differences between the mean-field approximation and the Bethe approximation, we have simulated agent behavior in a simple goal-reaching task with different types of uncertainties. Overall, the Bethe agent achieves higher success rates in reaching goal states. We relate the better performance of the Bethe agent to more accurate predictions about the consequences of its own actions. Consequently, active inference based on the Bethe approximation extends the application range of active inference to more complex behavioral tasks.},
author = {Schw{\"{o}}bel, Sarah and Kiebel, Stefan and Markovi{\'{c}}, Dimitrije},
booktitle = {Neural Computation},
doi = {10.1162/neco_a_01108},
file = {:home/esther/Desktop/bachelor/papers/Schw{\"{o}}bel{\_}2020{\_}ActInf{\_}BeliefProp{\_}BetheApprox.pdf:pdf},
issn = {1530888X},
month = {sep},
number = {9},
pages = {2530--2567},
pmid = {29949461},
publisher = {MIT Press Journals},
title = {{Active inference, belief propagation, and the Bethe approximation}},
volume = {30},
year = {2018}
}
@article{Smith2021,
abstract = {The active inference framework, and in particular its recent formulation as a partially observable Markov decision process (POMDP), has gained increasing popularity in recent years as a useful approach for modelling neurocognitive processes. This framework is highly general and flexible in its ability to be customized to model any cognitive process, as well as simulate predicted neuronal responses based on its accompanying neural process theory. It also affords both simulation experiments for proof of principle and behavioral modelling for empirical studies. However, there are limited resources that explain how to build and run these models in practice, which limits their widespread use. Most introductions assume a technical background in programming, mathematics, and machine learning. In this paper we offer a step-by-step tutorial on how to build POMDPs, run simulations using standard MATLAB routines, and fit these models to empirical data. We assume a minimal background in programming and mathematics, thoroughly explain all equations, and provide exemplar scripts that can be customized for both theoretical and empirical studies. Our goal is to provide the reader with the requisite background knowledge and practical tools to apply active inference to their own research. We also provide optional technical sections and several appendices, which offer the interested reader additional technical details. This tutorial should provide the reader with all the tools necessary to use these models and to follow emerging advances in active inference research.},
author = {Smith, Ryan and Friston, Karl J and Whyte, Christopher J},
doi = {10.31234/osf.io/b4jm6},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Tutorial{\_}paper{\_}final{\_}1{\_}1{\_}21{\_}FINALv7.2.3KFriston{\_}2021{\_}Tutorial.pdf:pdf},
journal = {Preprint},
number = {January},
pages = {1--104},
title = {{A Step-by-Step Tutorial on Active Inference and its Application to Empirical Data}},
year = {2021}
}
@article{Friston2013a,
abstract = {This paper considers agency in the setting of embodied or active inference. In brief, we associate a sense of agency with prior beliefs about action and ask what sorts of beliefs underlie optimal behavior. In particular, we consider prior beliefs that action minimizes the Kullback-Leibler (KL) divergence between desired states and attainable states in the future. This allows one to formulate bounded rationality as approximate Bayesian inference that optimizes a free energy bound on model evidence. We show that constructs like expected utility, exploration bonuses, soft max choice rules and optimism bias emerge as natural consequences of this formulation. Previous accounts of active inference have focused on predictive coding and Bayesian filtering schemes for minimizing free energy. Here, we consider variational Bayes as an alternative scheme that provides formal constraints on the computational anatomy of inference and action-constraints that are remarkably consistent with neuroanatomy. Furthermore, this scheme contextualizes optimal decision theory and economic (utilitarian) formulations as pure inference problems. For example, expected utility theory emerges as a special case of free energy minimization, where the sensitivity or inverse temperature (of soft max functions and quantal response equilibria) has a unique and Bayes-optimal solution-that minimizes free energy. This sensitivity corresponds to the precision of beliefs about behavior, such that attainable goals are afforded a higher precision or confidence. In turn, this means that optimal behavior entails a representation of confidence about outcomes that are under an agent's control. {\textcopyright} 2013 Friston, Schwartenbeck, FitzGerald, Moutoussis, Behrens and Dolan.},
author = {Friston, Karl and Schwartenbeck, Philipp and FitzGerald, Thomas and Moutoussis, Michael and Behrens, Timothy and Dolan, Raymond J.},
doi = {10.3389/fnhum.2013.00598},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friston et al. - 2013 - The anatomy of choice Active inference and agency.pdf:pdf},
issn = {16625161},
journal = {Frontiers in Human Neuroscience},
keywords = {Active inference,Agency,Bayesian,Bounded rationality,Embodied cognition,Free energy,Inference,Utility theory},
month = {sep},
number = {SEP},
publisher = {Frontiers Media S. A.},
title = {{The anatomy of choice: Active inference and agency}},
year = {2013}
}
@article{Millidge2020b,
abstract = {The Expected Free Energy (EFE) is a central quantity in the theory of active inference. It is the quantity that all active inference agents are mandated to minimize through action, and its decomposition into extrinsic and intrinsic value terms is key to the balance of exploration and exploitation that active inference agents evince. Despite its importance, the mathematical origins of this quantity and its relation to the Variational Free Energy (VFE) remain unclear. In this paper, we investigate the origins of the EFE in detail and show that it is not simply "the free energy in the future". We present a functional that we argue is the natural extension of the VFE, but which actively discourages exploratory behaviour, thus demonstrating that exploration does not directly follow from free energy minimization into the future. We then develop a novel objective, the Free-Energy of the Expected Future (FEEF), which possesses both the epistemic component of the EFE as well as an intuitive mathematical grounding as the divergence between predicted and desired futures.},
archivePrefix = {arXiv},
arxivId = {2004.08128},
author = {Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L.},
eprint = {2004.08128},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Millidge{\_}2020{\_}Exp{\_}FE.pdf:pdf},
journal = {arXiv},
title = {{Whence the Expected Free Energy?}},
year = {2020}
}
@misc{Solopchuk2020,
author = {Solopchuk, Oleg},
booktitle = {Sep 4, 2018},
pages = {1--21},
title = {{Tutorial on Active Inference. Active inference is the Free Energy{\ldots} | by Oleg Solopchuk | Medium}},
url = {https://medium.com/@solopchuk/tutorial-on-active-inference-30edcf50f5dc},
urldate = {2020-09-17},
year = {2020}
}
@article{Sims2016,
abstract = {Those who endorse the free energy principle as a theory of cognition (as well as a theory of biological homeostasis) are committed to three propositions that are jointly incompatible but which will cohere if one of them is denied. The first of these is that the free energy principle gives us a self-sufficient explanation of what all cognitive systems consist in: a specific computational architecture. The second is that all adaptive behavior is driven by the free energy principle and the process of model-based inference it entails. The third is that cognition is not ubiquitous. These three incompatible propositions together comprise a problem of scope for the free energy principle as a theory of cognition. The prospects for rejecting each of these propositions are considered. To drop either the first or the second would limit the explanatory success of the principle. However, there are plausible ways to bite the bullet on denial of the third proposition. In particular, I argue that it is possible for the free energy theorist to admit that cognition is ubiquitous in biological systems while reserving conceptual space exclusively for human cognitive capacities.},
author = {Sims, Andrew},
doi = {10.1080/09515089.2016.1200024},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Sims2016{\_}ScopeProblem{\_}FEP.pdf:pdf},
issn = {1465394X},
journal = {Philosophical Psychology},
keywords = {Homeostasis,minimal cognition,predictive processing},
number = {7},
pages = {967--980},
publisher = {Routledge},
title = {{A problem of scope for the free energy principle as a theory of cognition}},
url = {http://dx.doi.org/10.1080/09515089.2016.1200024},
volume = {29},
year = {2016}
}
@article{Colombo2017,
abstract = {Courtesy of its free energy formulation, the hierarchical predictive processing theory of the brain (PTB) is often claimed to be a grand unifying theory. To test this claim, we examine a central case: activity of mesocorticolimbic dopaminergic (DA) systems. After reviewing the three most prominent hypotheses of DA activity—the anhedonia, incentive salience, and reward prediction error hypotheses—we conclude that the evidence currently vindicates explanatory pluralism. This vindication implies that the grand unifying claims of advocates of PTB are unwarranted. More generally, we suggest that the form of scientific progress in the cognitive sciences is unlikely to be a single overarching grand unifying theory.},
author = {Colombo, Matteo and Wright, Cory},
doi = {10.1016/j.bandc.2016.02.003},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Wright{\_}2017{\_}prediction{\_}error{\_}FEP.pdf:pdf},
issn = {10902147},
journal = {Brain and Cognition},
keywords = {Anhedonia,Dopamine,Explanation,Explanatory pluralism,Free energy,Incentive salience,Predictive processing,Reduction,Reward prediction error,Unification},
number = {November},
pages = {3--12},
pmid = {26905647},
title = {{Explanatory pluralism: An unrewarding prediction error for free energy theorists}},
volume = {112},
year = {2017}
}
@misc{Andrews2020,
abstract = {The free energy principle (FEP) has seen extensive philosophical engagement— both from a general philosophy of science perspective and from the perspective of philosophies of specific sciences: cognitive science, neuroscience, and biology. The literature on the FEP has attempted to draw out specific philosophical commitments and entailments of the framework. But the most fundamental questions, from the perspective of philosophy of science, remain open: To what discipline(s) does the FEP belong? Does it make falsifiable claims? What sort of scientific object is it? Is it to be taken as a representation of contingent states of affairs in nature? Does it constitute knowledge? What role is it in- tended to play in relation to empirical research? Does the FEP even properly belong to the domain of science? To the extent that it has engaged with them at all, the extant literature has begged, dodged, dismissed, and skirted around these questions, without ever addressing them head-on. These questions must, I urge, be answered satisfactorily before we can make any headway on the philosophical consequences of the FEP. I take preliminary steps towards answering these questions in this paper, first by examining closely key formal elements of the framework and the implications they hold for its utility, and second, by highlighting potential modes of interpreting the FEP in light of an abundant philosophical literature on scientific modelling.},
author = {Andrews, Mel},
keywords = {Bayesian brain,demarcation problem,epistemic virtues,falsification,free energy principle,life-mind continuity,modelling,scientific models,scientific theories,simulations},
title = {{The Math is not the Territory: Navigating the Free Energy Principle}},
url = {http://philsci-archive.pitt.edu/18315/},
year = {2020}
}
@techreport{Fountas2020,
abstract = {Active inference is a Bayesian framework for understanding biological intelligence. The underlying theory brings together perception and action under one single imperative: minimizing free energy. However, despite its theoretical utility in explaining intelligence, computational implementations have been restricted to low-dimensional and idealized situations. In this paper, we present a neural architecture for building deep active inference agents operating in complex, continuous state-spaces using multiple forms of Monte-Carlo (MC) sampling. For this, we introduce a number of techniques, novel to active inference. These include: i) selecting free-energy-optimal policies via MC tree search, ii) approximating this optimal policy distribution via a feed-forward 'habitual' network, iii) predicting future parameter belief updates using MC dropouts and, finally, iv) optimizing state transition precision (a high-end form of attention). Our approach enables agents to learn environmental dynamics efficiently, while maintaining task performance , in relation to reward-based counterparts. We illustrate this in a new toy environment, based on the dSprites data-set, and demonstrate that active inference agents automatically create disentangled representations that are apt for modeling state transitions. In a more complex Animal-AI environment, our agents (using the same neural architecture) are able to simulate future state transitions and actions (i.e., plan), to evince reward-directed navigation-despite temporary suspension of visual input. These results show that deep active inference-equipped with MC methods-provides a flexible framework to develop biologically-inspired intelligent agents, with applications in both machine learning and cognitive science.},
archivePrefix = {arXiv},
arxivId = {2006.04176v2},
author = {Fountas, Zafeirios and Sajid, Noor and Mediano, Pedro A M and Friston, Karl},
eprint = {2006.04176v2},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fountas et al. - 2020 - Deep active inference agents using Monte-Carlo methods.pdf:pdf},
isbn = {2006.04176v2},
title = {{Deep active inference agents using Monte-Carlo methods}},
year = {2020}
}
@article{Bogacz2017c,
abstract = {This paper provides an easy to follow tutorial on the free-energy framework for modelling perception developed by Friston, which extends the predictive coding model of Rao and Ballard. These models assume that the sensory cortex infers the most likely values of attributes or features of sensory stimuli from the noisy inputs encoding the stimuli. Remarkably, these models describe how this inference could be implemented in a network of very simple computational elements, suggesting that this inference could be performed by biological networks of neurons. Furthermore, learning about the parameters describing the features and their uncertainty is implemented in these models by simple rules of synaptic plasticity based on Hebbian learning. This tutorial introduces the free-energy framework using very simple examples, and provides step-by-step derivations of the model. It also discusses in more detail how the model could be implemented in biological neural circuits. In particular, it presents an extended version of the model in which the neurons only sum their inputs, and synaptic plasticity only depends on activity of pre-synaptic and post-synaptic neurons.},
author = {Bogacz, Rafal},
doi = {10.1016/j.jmp.2015.11.003},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bogacz - 2017 - A tutorial on the free-energy framework for modelling perception and learning.pdf:pdf},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
month = {feb},
pages = {198--211},
pmid = {28298703},
publisher = {Academic Press Inc.},
title = {{A tutorial on the free-energy framework for modelling perception and learning}},
url = {http://dx.doi.org/10.1016/j.jmp.2015.11.003},
volume = {76},
year = {2017}
}
@incollection{Adams2015,
abstract = {This chapter discusses how many features of cortical anatomy and physiology can be understood in the light of a predictive coding theory of brain function. In Sect. 7.1, we briefly discuss the theoretical reasons to suppose that the brain is likely to use predictive coding. One key theoretical underpinning of predictive coding is the free energy principle, which argues that brains must maximize the evidence for their (generative) model of sensory inputs: A process of ‘active inference'. In Sect. 7.2, we discuss how active inference predicts commonalities in the extrinsic connections of sensory and motor systems. Such commonalities are found in their hierarchical structure (shown by laminar characteristics), their topography, their pharmacology and physiology. In Sect. 7.3, we show how the equations describing hierarchical message passing within a predictive coding scheme can be mapped on to key features of intrinsic connections, namely the canonical cortical microcircuit, and their implications for the oscillatory dynamics of different cell populations. In Sect. 7.4, we briefly review some empirical evidence for predictive coding in the brain.},
author = {Adams, Rick A. and Friston, Karl J. and Bastos, Andre M.},
booktitle = {Recent Advances On The Modular Organization Of The Cortex},
doi = {10.1007/978-94-017-9900-3_7},
isbn = {9789401799003},
keywords = {Active inference,Free energy,Hierarchy,Microcircuit,Predictive coding},
title = {{Active inference, predictive coding and cortical architecture}},
year = {2015}
}
@article{Friston2010c,
abstract = {We have previously tried to explain perceptual inference and learning under a free-energy principle that pursues Helmholtz's agenda to understand the brain in terms of energy minimization. It is fairly easy to show that making inferences about the causes of sensory data can be cast as the minimization of a free-energy bound on the likelihood of sensory inputs, given an internal model of how they were caused. In this article, we consider what would happen if the data themselves were sampled to minimize this bound. It transpires that the ensuing active sampling or inference is mandated by ergodic arguments based on the very existence of adaptive agents. Furthermore, it accounts for many aspects of motor behavior; from retinal stabilization to goal-seeking. In particular, it suggests that motor control can be understood as fulfilling prior expectations about proprioceptive sensations. This formulation can explain why adaptive behavior emerges in biological agents and suggests a simple alternative to optimal control theory. We illustrate these points using simulations of oculomotor control and then apply to same principles to cued and goal-directed movements. In short, the free-energy formulation may provide an alternative perspective on the motor control that places it in an intimate relationship with perception. {\textcopyright} 2010 Springer-Verlag.},
author = {Friston, Karl J. and Daunizeau, Jean and Kilner, James and Kiebel, Stefan J.},
doi = {10.1007/s00422-010-0364-z},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2010{\_}ActionAndBehavior.pdf:pdf},
issn = {03401200},
journal = {Biological Cybernetics},
keywords = {Bayesian,Computational,Control,Hierarchical,Motor,Priors},
number = {3},
pages = {227--260},
pmid = {20148260},
title = {{Action and behavior: A free-energy formulation}},
volume = {102},
year = {2010}
}
@article{Ramstead2018,
abstract = {The free-energy principle (FEP) is a formal model of neuronal processes that is widely recognised in neuroscience as a unifying theory of the brain and biobehaviour. More recently, however, it has been extended beyond the brain to explain the dynamics of living systems, and their unique capacity to avoid decay. The aim of this review is to synthesise these advances with a meta-theoretical ontology of biological systems called variational neuroethology, which integrates the FEP with Tinbergen's four research questions to explain biological systems across spatial and temporal scales. We exemplify this framework by applying it to Homo sapiens, before translating variational neuroethology into a systematic research heuristic that supplies the biological, cognitive, and social sciences with a computationally tractable guide to discovery.},
author = {Ramstead, Maxwell James D{\'{e}}sormeau and Badcock, Paul Benjamin and Friston, Karl John},
doi = {10.1016/j.plrev.2017.09.001},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramstead, Badcock, Friston - 2018 - Answering Schr{\"{o}}dinger's question A free-energy formulation.pdf:pdf},
issn = {15710645},
journal = {Physics of Life Reviews},
keywords = {Complex adaptive systems,Evolutionary systems theory,Free energy principle,Hierarchically mechanistic mind,Physics of the mind,Variational neuroethology},
month = {mar},
pages = {1--16},
pmid = {29029962},
publisher = {Elsevier B.V.},
title = {{Answering Schr{\"{o}}dinger's question: A free-energy formulation}},
volume = {24},
year = {2018}
}
@article{Friston2014,
abstract = {This paper considers goal-directed decision-making in terms of embodied or active inference. We associate bounded rationality with approximate Bayesian inference that optimizes a free energy bound on model evidence. Several constructs such as expected utility, exploration or novelty bonuses, softmax choice rules and optimism bias emerge as natural consequences of free energy minimization. Previous accounts of active inference have focused on predictive coding. In this paper, we consider variational Bayes as a scheme that the brain might use for approximate Bayesian inference. This scheme provides formal constraints on the computational anatomy of inference and action, which appear to be remarkably consistent with neuroanatomy. Active inference contextualizes optimal decision theory within embodied inference, where goals become prior beliefs. For example, expected utility theory emerges as a special case of free energy minimization, where the sensitivity or inverse temperature (associated with softmax functions and quantal response equilibria) has a unique and Bayes-optimal solution. Crucially, this sensitivity corresponds to the precision of beliefs about behaviour. The changes in precision during variational updates are remarkably reminiscent of empirical dopaminergic responses—and they may provide a new perspective on the role of dopamine in assimilating reward prediction errors to optimize decision-making.},
author = {Friston, Karl and Schwartenbeck, Philipp and FitzGerald, Thomas and Moutoussis, Michael and Behrens, Timothy and Dolan, Raymond J},
doi = {10.1098/rstb.2013.0481},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friston et al. - Unknown - Opinion piece The anatomy of choice dopamine and decision-making.pdf:pdf},
issn = {14712970},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Active inference,Agency,Bayesian inference,Bounded rationality,Free energy,Utility theory},
number = {1655},
pmid = {25267823},
title = {{The anatomy of choice: Dopamine and decision-making}},
url = {http://dx.doi.org/10.1098/rstb.2013.0481},
volume = {369},
year = {2014}
}
@article{Friston2018,
abstract = {Is self-consciousness necessary for consciousness? The answer is yes. So there you have it-the answer is yes. This was my response to a question I was asked to address in a recent AEON piece (https://aeon.co/essays/consciousness-is-not-a-thing-but-a-process-of-inference). What follows is based upon the notes for that essay, with a special focus on self-organization, self-evidencing and self-modeling. I will try to substantiate my (polemic) answer from the perspective of a physicist. In brief, the argument goes as follows: if we want to talk about creatures, like ourselves, then we have to identify the characteristic behaviors they must exhibit. This is fairly easy to do by noting that living systems return to a set of attracting states time and time again. Mathematically, this implies the existence of a Lyapunov function that turns out to be model evidence (i.e., self-evidence) in Bayesian statistics or surprise (i.e., self-information) in information theory. This means that all biological processes can be construed as performing some form of inference, from evolution through to conscious processing. If this is the case, at what point do we invoke consciousness? The proposal on offer here is that the mind comes into being when self-evidencing has a temporal thickness or counterfactual depth, which grounds inferences about the consequences of my action. On this view, consciousness is nothing more than inference about my future; namely, the self-evidencing consequences of what I could do.},
author = {Friston, Karl},
doi = {10.3389/fpsyg.2018.00579},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2018{\_}AmISelfconscious.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Active inference,Bayesian,Dynamics,Free energy,Model selection,Predictive processing,Variational},
month = {apr},
number = {APR},
pages = {1--10},
publisher = {Frontiers Media S.A.},
title = {{Am i self-conscious? (or does self-organization entail self-consciousness?)}},
volume = {9},
year = {2018}
}
@article{Volinsky1999,
abstract = {Standard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are. Bayesian model averaging (BMA) provides a coherent mechanism for accounting for this model uncertainty. Several methods for implementing BMA have recently emerged. We discuss these methods and present a number of examples. In these examples, BMA provides improved out-of- sample predictive performance. We also provide a catalogue of currently available BMA software.},
author = {Volinsky, Chris T. and Raftery, Adrian E. and Madigan, David and Hoeting, Jennifer A.},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/bayesian{\_}model{\_}averaging.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {and phrases,bayesian graphical,bayesian model averaging,learning,markov chain monte carlo,model uncertainty,models},
number = {4},
pages = {382--417},
title = {{David Draper and E. I. George, and a rejoinder by the authors}},
volume = {14},
year = {1999}
}
@article{Linson2018,
abstract = {The emerging neurocomputational vision of humans as embodied, ecologically embedded, social agents-who shape and are shaped by their environment-offers a golden opportunity to revisit and revise ideas about the physical and information-theoretic underpinnings of life, mind, and consciousness itself. In particular, the active inference framework (AIF) makes it possible to bridge connections from computational neuroscience and robotics/AI to ecological psychology and phenomenology, revealing common underpinnings and overcoming key limitations. AIF opposes the mechanistic to the reductive, while staying fully grounded in a naturalistic and information-theoretic foundation, using the principle of free energy minimization. The latter provides a theoretical basis for a unified treatment of particles, organisms, and interactive machines, spanning from the inorganic to organic, non-life to life, and natural to artificial agents. We provide a brief introduction to AIF, then explore its implications for evolutionary theory, ecological psychology, embodied phenomenology, and robotics/AI research. We conclude the paper by considering implications for machine consciousness.},
author = {Linson, Adam and Clark, Andy and Ramamoorthy, Subramanian and Friston, Karl},
doi = {10.3389/frobt.2018.00021},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chella et al. - 2018 - the active inference approach to ecological perception General information dynamics for natural and artificial em.pdf:pdf},
issn = {22969144},
journal = {Frontiers Robotics AI},
keywords = {Affordances,Embodiment,Evolution,Frame problem,Free energy,Self-organization,Skilled expertise,Uncertainty},
number = {MAR},
title = {{The active inference approach to ecological perception: General information dynamics for natural and artificial embodied cognition}},
url = {www.frontiersin.org},
volume = {5},
year = {2018}
}
@article{Sajid2019,
abstract = {Active inference is a first principle account of how autonomous agents operate in dynamic, non-stationary environments. This problem is also considered in reinforcement learning (RL), but limited work exists on comparing the two approaches on the same discrete-state environments. In this paper, we provide: 1) an accessible overview of the discrete-state formulation of active inference, highlighting natural behaviors in active inference that are generally engineered in RL; 2) an explicit discrete-state comparison between active inference and RL on an OpenAI gym baseline. We begin by providing a condensed overview of the active inference literature, in particular viewing the various natural behaviors of active inference agents through the lens of RL. We show that by operating in a pure belief-based setting, active inference agents can carry out epistemic exploration, and account for uncertainty about their environment in a Bayes-optimal fashion. Furthermore, we show that the reliance on an explicit reward signal in RL is removed in active inference, where reward can simply be treated as another observation; even in the total absence of rewards, agent behaviors are learned through preference learning. We make these properties explicit by showing two scenarios in which active inference agents can infer behaviors in reward-free environments compared to both Q-learning and Bayesian model-based RL agents; by placing zero prior preferences over rewards and by learning the prior preferences over the observations corresponding to reward. We conclude by noting that this formalism can be applied to more complex settings if appropriate generative models can be formulated. In short, we aim to demystify the behavior of active inference agents by presenting an accessible discrete state-space and time formulation, and demonstrate these behaviors in a OpenAI gym environment, alongside RL agents.},
archivePrefix = {arXiv},
arxivId = {1909.10863},
author = {Sajid, Noor and Ball, Philip J. and Parr, Thomas and Friston, Karl J.},
eprint = {1909.10863},
file = {:home/esther/Desktop/bachelor/papers/Sajid{\_}2020{\_}ActInf{\_}Demystified.pdf:pdf},
number = {0},
pages = {1--69},
title = {{Active inference: demystified and compared}},
url = {http://arxiv.org/abs/1909.10863},
volume = {44},
year = {2019}
}
@article{Hamilton2018,
abstract = {The Anthropocene is a proposed new epoch to be added to the Geological Time Scale describing the very recent rupture in the functioning of the Earth System as a whole arising from the impact of human activity. The kinds of human activity capable of disrupting the Earth System have to be separated from those that merely alter the landscape or interfere in an ecosystem. The concept required the emergence of Earth System science in the 1980s and 1990s. Other scientific approaches have misconstrued it, often in debates over the new epoch's starting date. It involves the unique features of complex systems, and has been enriched by climate science. The idea of the Anthropocene has led to research integrating stratigraphy with Earth System science. Social scientists, noting the remarkable convergence of human and natural history in the Anthropocene, have advanced various critiques of the idea, most of them reflecting a deep epistemological divide over the nature and scope of kinds of knowledge. Humanists build on the science as given, while posthumanists view the Anthropocene as a vindication of their criticism of notions of human agency and Cartesian dualism. The critique of anthropocentrism is applied to the Anthropocene, both the term and even the ‘objective' nature of it.},
author = {Hamilton, Clive},
doi = {10.1016/B978-0-12-409548-9.10614-1},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamilton - 2018 - The anthropocene.pdf:pdf},
isbn = {9780444641304},
journal = {Encyclopedia of Ecology},
keywords = {Agency,Anthropocene,Anthropocene working group,Anthropocentrism,Cartesian dualism,Complex system,Earth system,Earth system science,Posthumanism,Stratigraphy},
number = {41},
pages = {239--246},
title = {{The anthropocene}},
year = {2018}
}
@article{Friston2013,
abstract = {This paper presents a heuristic proof (and simulations of a primordial soup) suggesting that life-or biological self-organization-is an inevitable and emergent property of any (ergodic) random dynamical system that possesses a Markov blanket. This conclusion is based on the following arguments: if the coupling among an ensemble of dynamical systems is mediated by short-range forces, then the states of remote systems must be conditionally independent. These independencies induce a Markov blanket that separates internal and external states in a statistical sense. The existence of a Markov blanket means that internal states will appear to minimize a free energy functional of the states of their Markov blanket. Crucially, this is the same quantity that is optimized in Bayesian inference. Therefore, the internal states (and their blanket) will appear to engage in active Bayesian inference. In other words, they will appear to model-and act on-their world to preserve their functional and structural integrity, leading to homoeostasis and a simple form of autopoiesis. {\textcopyright} 2013 The Author(s).},
author = {Friston, Karl},
doi = {10.1098/rsif.2013.0475},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friston - 2013 - Life as we know it.pdf:pdf},
issn = {17425662},
journal = {Journal of the Royal Society Interface},
keywords = {Active inference,Autopoiesis,Ergodicity,Free energy,Random attractor,Self-organization},
month = {sep},
number = {86},
pmid = {23825119},
publisher = {Royal Society},
title = {{Life as we know it}},
volume = {10},
year = {2013}
}
@article{Ueltzhoffer2018,
abstract = {This work combines the free energy principle and the ensuing active inference dynamics with recent advances in variational inference in deep generative models, and evolution strategies to introduce the “deep active inference” agent. This agent minimises a variational free energy bound on the average surprise of its sensations, which is motivated by a homeostatic argument. It does so by optimising the parameters of a generative latent variable model of its sensory inputs, together with a variational density approximating the posterior distribution over the latent variables, given its observations, and by acting on its environment to actively sample input that is likely under this generative model. The internal dynamics of the agent are implemented using deep and recurrent neural networks, as used in machine learning, making the deep active inference agent a scalable and very flexible class of active inference agent. Using the mountain car problem, we show how goal-directed behaviour can be implemented by defining appropriate priors on the latent states in the agent's model. Furthermore, we show that the deep active inference agent can learn a generative model of the environment, which can be sampled from to understand the agent's beliefs about the environment and its interaction therewith.},
archivePrefix = {arXiv},
arxivId = {1709.02341},
author = {Ueltzh{\"{o}}ffer, Kai},
doi = {10.1007/s00422-018-0785-7},
eprint = {1709.02341},
issn = {14320770},
journal = {Biological Cybernetics},
keywords = {Action,Cognition,Deep learning,Generative models,Perception,Variational inference},
pmid = {30350226},
title = {{Deep active inference}},
year = {2018}
}
@misc{Catal2019,
abstract = {Learning to take actions based on observations is a core requirement for artificial agents to be able to be successful and robust at their task. Reinforcement Learning (RL) is a well-known technique for learning such policies. However, current RL algorithms often have to deal with reward shaping, have difficulties generalizing to other environments and are most often sample inefficient. In this paper, we explore active inference and the free energy principle, a normative theory from neuroscience that explains how self-organizing biological systems operate by maintaining a model of the world and casting action selection as an inference problem. We apply this concept to a typical problem known to the RL community, the mountain car problem, and show how active inference encompasses both RL and learning from demonstrations.},
archivePrefix = {arXiv},
arxivId = {1904.08149},
author = {{\c{C}}atal, Ozan and Nauta, Johannes and Verbelen, Tim and Simoens, Pieter and Dhoedt, Bart},
booktitle = {arXiv},
eprint = {1904.08149},
issn = {23318422},
month = {apr},
publisher = {arXiv},
title = {{Bayesian policy selection Using active inference}},
year = {2019}
}
@article{Friston2012,
abstract = {Recent years have seen the emergence of an important new fundamental theory of brain function. This theory brings information-theoretic, Bayesian, neuroscientific, and machine learning approaches into a single framework whose overarching principle is the minimiza- tion of surprise (or, equivalently, the maximization of expectation).The most comprehensive such treatment is the "free-energy minimization" formulation due to Karl Friston (see e.g., Friston and Stephan, 2007; Friston, 2010a,b - see also Fiorillo, 2010; Thornton, 2010). A recurrent puzzle raised by critics of these models is that biological systems do not seem to avoid surprises. We do not simply seek a dark, unchanging chamber, and stay there.This is the "Dark-Room Problem." Here, we describe the problem and further unpack the issues to which it speaks. Using the same format as the prolog of Eddington's Space, Time, and Gravitation (Eddington, 1920) we present our discussion as a conversation between: an information theorist (Thornton), a physicist (Friston), and a philosopher (Clark). {\textcopyright} 2012 Friston, Thornton and Clark.},
author = {Friston, Karl and Thornton, Christopher and Clark, Andy},
doi = {10.3389/fpsyg.2012.00130},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2012{\_}dark{\_}room.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Bayesian brain,Free-energy principle,Optimality,Surprise},
number = {MAY},
pages = {1--7},
title = {{Free-energy minimization and the dark-room problem}},
volume = {3},
year = {2012}
}
@article{Friston2016,
abstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},
author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O'Doherty, John and Pezzulo, Giovanni},
doi = {10.1016/j.neubiorev.2016.06.022},
file = {:home/esther/Desktop/bachelor/papers/KFriston{\_}2016{\_}ActInf{\_}Learning.pdf:pdf},
issn = {18737528},
journal = {Neuroscience and Biobehavioral Reviews},
keywords = {Active inference,Bayesian inference,Bayesian surprise,Epistemic value,Exploitation,Exploration,Free energy,Goal-directed,Habit learning,Information gain},
pages = {862--879},
pmid = {27375276},
publisher = {Elsevier Ltd},
title = {{Active inference and learning}},
url = {http://dx.doi.org/10.1016/j.neubiorev.2016.06.022},
volume = {68},
year = {2016}
}
@techreport{Friston2020,
abstract = {This technical report describes a dynamic causal model of the spread of coronavirus through a population. The model is based upon ensemble or population dynamics that generate outcomes, like new cases and deaths over time. The purpose of this model is to quantify the uncertainty that attends predictions of relevant outcomes. By assuming suitable conditional dependencies, one can model the effects of interventions (e.g., social distancing) and differences among populations (e.g., herd immunity) to predict what might happen in different circumstances. Technically, this model leverages state-of-the-art variational (Bayesian) model inversion and comparison procedures, originally developed to characterise the responses of neuronal ensembles to perturbations. Here, this modelling is applied to epidemiological populations—to illustrate the kind of inferences that are supported and how the model per se can be optimised given timeseries data. Although the purpose of this paper is to describe a modelling protocol, the results illustrate some interesting perspectives on the current pandemic; for example, the nonlinear effects of herd immunity that speak to a self-organised mitigation process.},
author = {Friston, Karl and Parr, Thomas and Zeidman, Peter and Razi, Adeel and Flandin, Guillaume and Daunizeau, Jean and Hulme, J and Billig, Alexander J and Litvak, Vladimir and Moran, Rosalyn J and Price, Cathy J},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friston et al. - Unknown - COVID-19.pdf:pdf},
keywords = {Bayesian,compartmental models,coronavirus,dynamic causal modelling,epidemiology,variational},
pages = {1--43},
title = {{COVID-19}},
year = {2020}
}
@misc{Spratling2017,
abstract = {Predictive coding is a leading theory of how the brain performs probabilistic inference. However, there are a number of distinct algorithms which are described by the term “predictive coding”. This article provides a concise review of these different predictive coding algorithms, highlighting their similarities and differences. Five algorithms are covered: linear predictive coding which has a long and influential history in the signal processing literature; the first neuroscience-related application of predictive coding to explaining the function of the retina; and three versions of predictive coding that have been proposed to model cortical function. While all these algorithms aim to fit a generative model to sensory data, they differ in the type of generative model they employ, in the process used to optimise the fit between the model and sensory data, and in the way that they are related to neurobiology.},
author = {Spratling, M. W.},
booktitle = {Brain and Cognition},
doi = {10.1016/j.bandc.2015.11.003},
issn = {10902147},
keywords = {Cortex,Free energy,Neural networks,Predictive coding,Retina,Signal processing},
pages = {92--97},
pmid = {26809759},
title = {{A review of predictive coding algorithms}},
volume = {112},
year = {2017}
}
@article{Hohwy,
abstract = {The free energy principle says that any self-organising system that is at nonequilibrium steady-state with its environment must minimize its (variational) free energy. It is proposed as a grand unifying principle for cognitive science and biology. The principle can appear cryptic, esoteric, too ambitious, and unfalsifiable-suggesting it would be best to suspend any belief in the principle, and instead focus on individual, more concrete and falsifiable 'process theories' for particular biological processes and phenomena like perception, decision and action. Here, I explain the free energy principle, and I argue that it is best understood as offering a conceptual and mathematical analysis of the concept of existence of self-organising systems. This analysis offers a new type of solution to long-standing problems in neurobiology, cognitive science, machine learning and philosophy concerning the possibility of normatively constrained, self-supervised learning and inference. The principle can therefore uniquely serve as a regulatory principle for process theories, to ensure that process theories conforming to it enable self-supervision. This is, at least for those who believe self-supervision is a foundational explanatory task, good reason to believe the free energy principle.},
author = {Hohwy, Jakob},
doi = {10.1007/s11229-020-02622-2},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hohwy - Unknown - Self-supervision, normativity and the free energy principle.pdf:pdf},
journal = {NEUROSCIENCE AND ITS PHILOSOPHY},
keywords = {Active inference,Free energy principle,Normativity,Predictive processing,Principles,Process theories,Self-evidencing,Self-organisation,Self-supervision,Unsupervised learning},
title = {{Self-supervision, normativity and the free energy principle}},
url = {https://doi.org/10.1007/s11229-020-02622-2},
year = {2020}
}
@article{Hutson2018,
abstract = {![Figure][1]{\textless}/img{\textgreater} The same algorithm can learn to walk in wildly different ways. IMAGES: YUVAL TASSA Last year, computer scientists at the University of Montreal (U of M) in Canada were eager to show off a new speech recognition algorithm, and they wanted to compare it to a benchmark, an algorithm from a well-known scientist. The only problem: The benchmark's source code wasn't published. The researchers had to recreate it from the published description. But they couldn't get their version to match the benchmark's claimed performance, says Nan Rosemary Ke, a Ph.D. student in the U of M lab. “We tried for 2 months and we couldn't get anywhere close.” The booming field of artificial intelligence (AI) is grappling with a replication crisis, much like the ones that have afflicted psychology, medicine, and other fields over the past decade. AI researchers have found it difficult to reproduce many key results, and that is leading to a new conscientiousness about research methods and publication protocols. “I think people outside the field might assume that because we have code, reproducibility is kind of guaranteed,” says Nicolas Rougier, a computational neuroscientist at France's National Institute for Research in Computer Science and Automation in Bordeaux. “Far from it.” Last week, at a meeting of the Association for the Advancement of Artificial Intelligence (AAAI) in New Orleans, Louisiana, reproducibility was on the agenda, with some teams diagnosing the problem—and one laying out tools to mitigate it. The most basic problem is that researchers often don't share their source code. At the AAAI meeting, Odd Erik Gundersen, a computer scientist at the Norwegian University of Science and Technology in Trondheim, reported the results of a survey of 400 algorithms presented in papers at two top AI conferences in the past few years. He found that only 6{\%} of the presenters shared the algorithm's code. Only a third shared the data they tested their algorithms on, and just half shared “pseudocode”—a limited summary of an algorithm. (In many cases, code is also absent from AI papers published in journals, including Science and Nature .) Researchers say there are many reasons for the missing details: The code might be a work in progress, owned by a company, or held tightly by a researcher eager to stay ahead of the competition. It might be dependent on other code, itself unpublished. Or it might be that the code is simply lost, on a crashed disk or stolen laptop—what Rougier calls the “my dog ate my program” problem. Assuming you can get and run the original code, it still might not do what you expect. In the area of AI called machine learning, in which computers derive expertise from experience, the training data for an algorithm can influence its performance. Ke suspects that not knowing the training for the speech-recognition benchmark was what tripped up her group. “There's randomness from one run to another,” she says. You can get “really, really lucky and have one run with a really good number,” she adds. “That's usually what people report.” At the AAAI meeting, Peter Henderson, a computer scientist at McGill University in Montreal, showed that the performance of AIs designed to learn by trial and error is highly sensitive not only to the exact code used, but also to the random numbers generated to kick off training, and to “hyperparameters”—settings that are not core to the algorithm but that affect how quickly it learns. He ran several of these “reinforcement learning” algorithms under different conditions and found wildly different results. For example, a virtual “half-cheetah”—a stick figure used in motion algorithms—could learn to sprint in one test but would flail around on the floor in another. Henderson says researchers should document more of these key details. “We're trying to push the field to have better experimental procedures, better evaluation methods,” he says. ![Figure][1]{\textless}/img{\textgreater} CREDITS: (GRAPHIC) E. HAND/ SCIENCE ; (DATA) GUNDERSEN AND KJENSMO, ASSOCIATION FOR THE ADVANCEMENT OF ARTIFICIAL INTELLIGENCE 2018 Henderson's experiment was conducted in a test bed for reinforcement learning algorithms called Gym, created by OpenAI, a nonprofit based in San Francisco, California. John Schulman, a computer scientist at OpenAI who helped create Gym, says that it helps standardize experiments. “Before Gym, a lot of people were working on reinforcement learning, but everyone kind of cooked up their own environments for their experiments, and that made it hard to compare results across papers,” he says. IBM Research presented another tool at the AAAI meeting to aid replication: a system for recreating unpublished source code automatically, saving researchers days or weeks of effort. It's a neural network—a machine learning algorithm made of layers of small computational units, analogous to neurons—that is designed to recreate other neural networks. It scans an AI research paper looking for a chart or diagram describing a neural net, parses those data into layers and connections, and generates the network in new code. The tool has now reproduced hundreds of published neural networks, and IBM is planning to make them available in an open, online repository. Joaquin Vanschoren, a computer scientist at Eindhoven University of Technology in the Netherlands, has created another repository for would-be replicators: a website called OpenML. It hosts not only algorithms, but also data sets and more than 8 million experimental runs with all their attendant details. “The exact way that you run your experiments is full of undocumented assumptions and decisions,” Vanschoren says. “A lot of this detail never makes it into papers.” Psychology has dealt with its reproducibility crisis in part by creating a culture that favors replication, and AI is starting to do the same. In 2015, Rougier helped start ReScience , a computer science journal dedicated to replications. The large Neural Information Processing Systems conference has started linking from its website to papers' source code when available. And Ke is helping organize a “reproducibility challenge,” in which researchers are invited to try to replicate papers submitted for an upcoming conference. Ke says nearly 100 replications are in progress, mostly by students, who may receive academic credit for their efforts. Yet AI researchers say the incentives are still not aligned with reproducibility. They don't have time to test algorithms under every condition, or the space in articles to document every hyperparameter they tried. They feel pressure to publish quickly, given that many papers are posted online to arXiv every day without peer review. And many are reluctant to report failed replications. At ReScience , for example, all the published replications have so far been positive. Rougier says he's been told of failed attempts, but young researchers often don't want to be seen as criticizing senior researchers. That's one reason why Ke declined to name the researcher behind the speech recognition algorithm she wanted to use as a benchmark. Gundersen says the culture needs to change. “It's not about shaming,” he says. “It's just about being honest.” [1]: pending:yes},
author = {Hutson, Matthew},
doi = {10.1126/science.359.6377.725},
issn = {0036-8075},
journal = {Science},
title = {{Artificial intelligence faces reproducibility crisis}},
year = {2018}
}
@article{schrodinger1945,
abstract = {Based on lectures delivered under the auspices of the Institute [for Advanced Studies] at Trinity College, Dublin, in February 1943.},
author = {Schr{\"{o}}dinger, Erwin},
doi = {10.1086/281292},
issn = {0003-0147},
journal = {The American Naturalist},
title = {{What is Life? The Physical Aspect of the Living Cell.}},
url = {http://www.whatislife.ie/downloads/What-is-Life.pdf},
year = {1945}
}
@article{Botvinick2012,
abstract = {Recent developments in decision-making research are bringing the topic of planning back to center stage in cognitive science. This renewed interest reopens an old, but still unanswered question: how exactly does planning happen? What are the underlying information processing operations and how are they implemented in the brain? Although a range of interesting possibilities exists, recent work has introduced a potentially transformative new idea, according to which planning is accomplished through probabilistic inference. {\textcopyright} 2012.},
author = {Botvinick, Matthew and Toussaint, Marc},
doi = {10.1016/j.tics.2012.08.006},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Botvinick{\_}2012{\_}PlanningAsInference.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {10},
pages = {485--488},
pmid = {22940577},
title = {{Planning as inference}},
volume = {16},
year = {2012}
}
@article{Andrews2018,
author = {Andrews, Mel},
file = {:home/esther/Desktop/bachelor/papers/Andrews{\_}FEP{\_}Primer.pdf:pdf},
number = {May},
pages = {1--16},
title = {{The Free Energy Principle: An Accessible Introduction to its Derivations, Applications, {\&} Implications}},
year = {2018}
}
@article{Colombo2018,
abstract = {The free-energy principle states that all systems that minimize their free energy resist a tendency to physical disintegration. Originally proposed to account for perception, learning, and action, the free-energy principle has been applied to the evolution, development, morphology, anatomy and function of the brain, and has been called a postulate, an unfalsifiable principle, a natural law, and an imperative. While it might afford a theoretical foundation for understanding the relationship between environment, life, and mind, its epistemic status is unclear. Also unclear is how the free-energy principle relates to prominent theoretical approaches to life science phenomena, such as organicism and mechanism. This paper clarifies both issues, and identifies limits and prospects for the free-energy principle as a first principle in the life sciences.},
author = {Colombo, Matteo and Wright, Cory},
doi = {10.1007/s11229-018-01932-w},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Colombo-Wright2018{\_}Article{\_}FirstPrinciplesInTheLifeScienc.pdf:pdf},
isbn = {1122901801},
issn = {15730964},
journal = {Synthese},
keywords = {Adaptation,Free energy,Life,Mechanism,Organicism},
publisher = {Springer Netherlands},
title = {{First principles in the life sciences: the free-energy principle, organicism, and mechanism}},
url = {https://doi.org/10.1007/s11229-018-01932-w},
year = {2018}
}
@article{DaCosta2020,
abstract = {Active inference is a normative principle underwriting perception, action, planning, decision-making and learning in biological or artificial agents. From its inception, its associated process theory has grown to incorporate complex generative models, enabling simulation of a wide range of complex behaviours. Due to successive developments in active inference, it is often difficult to see how its underlying principle relates to process theories and practical implementation. In this paper, we try to bridge this gap by providing a complete mathematical synthesis of active inference on discrete state-space models. This technical summary provides an overview of the theory, derives neuronal dynamics from first principles and relates this dynamics to biological processes. Furthermore, this paper provides a fundamental building block needed to understand active inference for mixed generative models; allowing continuous sensations to inform discrete representations. This paper may be used as follows: to guide research towards outstanding challenges, a practical guide on how to implement active inference to simulate experimental behaviour, or a pointer towards various in-silico neurophysiological responses that may be used to make empirical predictions.},
archivePrefix = {arXiv},
arxivId = {2001.07203},
author = {{Da Costa}, Lancelot and Parr, Thomas and Sajid, Noor and Veselic, Sebastijan and Neacsu, Victorita and Friston, Karl},
doi = {10.1016/j.jmp.2020.102447},
eprint = {2001.07203},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Da Costa et al. - 2020 - Active inference on discrete state-spaces A synthesis.pdf:pdf},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
keywords = {Active inference,Free energy principle,Markov decision process,Mathematical review,Process theory,Variational Bayesian inference},
month = {dec},
pages = {102447},
publisher = {Academic Press Inc.},
title = {{Active inference on discrete state-spaces: A synthesis}},
volume = {99},
year = {2020}
}
@article{Friston2015,
abstract = {We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (defined in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes-optimal) precision of beliefs about, or confidence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms.},
author = {Friston, Karl and Rigoli, Francesco and Ognibene, Dimitri and Mathys, Christoph and Fitzgerald, Thomas and Pezzulo, Giovanni},
doi = {10.1080/17588928.2015.1020053},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2017Actinf{\_}epistemic{\_}value.pdf:pdf},
issn = {17588936},
journal = {Cognitive Neuroscience},
keywords = {Active inference,Agency,Bayesian inference,Bayesian surprise,Bounded rationality,Epistemic value,Exploitation,Exploration,Free energy,Information gain,Utility theory},
number = {4},
pages = {187--214},
pmid = {25689102},
title = {{Active inference and epistemic value}},
volume = {6},
year = {2015}
}
@article{Parr2019,
abstract = {Active inference is an approach to understanding behaviour that rests upon the idea that the brain uses an internal generative model to predict incoming sensory data. The fit between this model and data may be improved in two ways. The brain could optimise probabilistic beliefs about the variables in the generative model (i.e. perceptual inference). Alternatively, by acting on the world, it could change the sensory data, such that they are more consistent with the model. This implies a common objective function (variational free energy) for action and perception that scores the fit between an internal model and the world. We compare two free energy functionals for active inference in the framework of Markov decision processes. One of these is a functional of beliefs (i.e. probability distributions) about states and policies, but a function of observations, while the second is a functional of beliefs about all three. In the former (expected free energy), prior beliefs about outcomes are not part of the generative model (because they are absorbed into the prior over policies). Conversely, in the second (generalised free energy), priors over outcomes become an explicit component of the generative model. When using the free energy function, which is blind to future observations, we equip the generative model with a prior over policies that ensure preferred (i.e. priors over) outcomes are realised. In other words, if we expect to encounter a particular kind of outcome, this lends plausibility to those policies for which this outcome is a consequence. In addition, this formulation ensures that selected policies minimise uncertainty about future outcomes by minimising the free energy expected in the future. When using the free energy functional—that effectively treats future observations as hidden states—we show that policies are inferred or selected that realise prior preferences by minimising the free energy of future expectations. Interestingly, the form of posterior beliefs about policies (and associated belief updating) turns out to be identical under both formulations, but the quantities used to compute them are not.},
author = {Parr, Thomas and Friston, Karl J.},
doi = {10.1007/s00422-019-00805-w},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Parr-Friston2019{\_}Article{\_}GeneralisedFreeEnergyAndActive.pdf:pdf},
isbn = {0123456789},
issn = {14320770},
journal = {Biological Cybernetics},
keywords = {Active inference,Bayesian,Data selection,Epistemic value,Free energy,Intrinsic motivation},
number = {5-6},
pages = {495--513},
pmid = {31562544},
publisher = {Springer Berlin Heidelberg},
title = {{Generalised free energy and active inference}},
url = {https://doi.org/10.1007/s00422-019-00805-w},
volume = {113},
year = {2019}
}
@article{Friston2010,
abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework. {\textcopyright} 2010 Macmillan Publishers Limited. All rights reserved.},
author = {Friston, Karl},
doi = {10.1038/nrn2787},
file = {:home/esther/Desktop/bachelor/papers/KFriston{\_}2010{\_}FreeEnergy{\_}BrainTheory.pdf:pdf},
issn = {1471003X},
journal = {Nature Reviews Neuroscience},
month = {feb},
number = {2},
pages = {127--138},
pmid = {20068583},
title = {{The free-energy principle: A unified brain theory?}},
volume = {11},
year = {2010}
}
@article{Cullen2018,
abstract = {Background: Artificial intelligence has recently attained humanlike performance in a number of gamelike domains. These advances have been spurred by brain-inspired architectures and algorithms such as hierarchical filtering and reinforcement learning. OpenAI Gym is an open-source platform in which to train, test, and benchmark algorithms—it provides a range of tasks, including those of classic arcade games such as Doom. Here we describe how the platform might be used as a simulation, test, and diagnostic paradigm for psychiatric conditions. Methods: To illustrate how active inference models of game play could be used to test mechanistic and algorithmic properties of psychiatric disorders, we provide two exemplar analyses. The first speaks to the impact of aging on cognition, examining game-play behaviors in a model of aging in which we compared age-dependent changes of younger (n = 9, 22 ± 1 years of age) and older (n = 7, 56 ± 5 years of age) adult players. The second is an illustration of a putative feature of anhedonia in which we simulated diminished sensitivity to reward. Results: These simulations demonstrate how active inference can be used to test predicted changes in both neurobiology and beliefs in psychiatric cohorts. We show that, as well as behavioral measures, putative neural correlates of active inference can be simulated, and hypothesized (model-based) differences in local field potentials and blood oxygen level–dependent responses can be produced. Conclusions: We show that active inference, through epistemic and value-based goals, enables simulated subjects to actively develop detailed representations of gaming environments, and we demonstrate the use of a principled algorithmic and neurobiological framework for testing hypotheses in psychiatric illness.},
author = {Cullen, Maell and Davey, Ben and Friston, Karl J. and Moran, Rosalyn J.},
doi = {10.1016/j.bpsc.2018.06.010},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Cullen{\_}2018{\_}ActInf{\_}Doom.pdf:pdf},
issn = {24519030},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
keywords = {Active inference,Computational phenotyping,Computational psychiatry,Free energy principle,Game-based imaging biomarkers,Markov decision process},
number = {9},
pages = {809--818},
pmid = {30082215},
publisher = {Society of Biological Psychiatry},
title = {{Active Inference in OpenAI Gym: A Paradigm for Computational Investigations Into Psychiatric Illness}},
url = {https://doi.org/10.1016/j.bpsc.2018.06.010},
volume = {3},
year = {2018}
}
@article{Friston2009,
abstract = {This paper questions the need for reinforcement learning or control theory when optimising behaviour. We show that it is fairly simple to teach an agent complicated and adaptive behaviours using a free-energy formulation of perception. In this formulation, agents adjust their internal states and sampling of the environment to minimize their free-energy. Such agents learn causal structure in the environment and sample it in an adaptive and self-supervised fashion. This results in behavioural policies that reproduce those optimised by reinforcement learning and dynamic programming. Critically, we do not need to invoke the notion of reward, value or utility. We illustrate these points by solving a benchmark problem in dynamic programming; namely the mountain-car problem, using active perception or inference under the free-energy principle. The ensuing proof-of-concept may be important because the free-energy formulation furnishes a unified account of both action and perception and may speak to a reappraisal of the role of dopamine in the brain. {\textcopyright} 2009 Friston et al.},
author = {Friston, Karl and Daunizeau, Jean and Kiebel, Stefan J.},
doi = {10.1371/journal.pone.0006421},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2009{\_}RLorActiveInference.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {7},
pmid = {19641614},
title = {{Reinforcement learning or active inference?}},
volume = {4},
year = {2009}
}
@article{Friston2020,
abstract = {We recently described a dynamic causal model of a COVID-19 outbreak within a single region. Here, we combine several of these (epidemic) models to create a (pandemic) model of viral spread among regions. Our focus is on a second wave of new cases that may result from loss of immunity--and the exchange of people between regions--and how mortality rates can be ameliorated under different strategic responses. In particular, we consider hard or soft social distancing strategies predicated on national (Federal) or regional (State) estimates of the prevalence of infection in the population. The modelling is demonstrated using timeseries of new cases and deaths from the United States to estimate the parameters of a factorial (compartmental) epidemiological model of each State and, crucially, coupling between States. Using Bayesian model reduction, we identify the effective connectivity between States that best explains the initial phases of the outbreak in the United States. Using the ensuing posterior parameter estimates, we then evaluate the likely outcomes of different policies in terms of mortality, working days lost due to lockdown and demands upon critical care. The provisional results of this modelling suggest that social distancing and loss of immunity are the two key factors that underwrite a return to endemic equilibrium.},
archivePrefix = {arXiv},
arxivId = {2004.13017},
author = {Friston, Karl and Parr, Thomas and Zeidman, Peter and Razi, Adeel and Flandin, Guillaume and Daunizeau, Jean and Hulme, Oliver J. and Billig, Alexander J and Litvak, Vladimir and Price, Cathy J and Moran, Rosalyn J and Lambert, Christian},
eprint = {2004.13017},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2020{\_}covid19{\_}USA.pdf:pdf},
pages = {1--35},
title = {{Second waves, social distancing, and the spread of COVID-19 across America}},
url = {http://arxiv.org/abs/2004.13017},
year = {2020}
}
@article{McGregor2015,
abstract = {Research on the so-called "free-energy principle'' (FEP) in cognitive neuroscience is becoming increasingly high-profile. To date, introductions to this theory have proved difficult for many readers to follow, but it depends mainly upon two relatively simple ideas: firstly that normative or teleological values can be expressed as probability distributions (active inference), and secondly that approximate Bayesian reasoning can be effectively performed by gradient descent on model parameters (the free-energy principle). The notion of active inference is of great interest for a number of disciplines including cognitive science and artificial intelligence, as well as cognitive neuroscience, and deserves to be more widely known. This paper attempts to provide an accessible introduction to active inference and informational free-energy, for readers from a range of scientific backgrounds. In this work introduce an agent-based model with an agent trying to make predictions about its position in a one-dimensional discretized world using methods from the FEP.},
archivePrefix = {arXiv},
arxivId = {1503.04187},
author = {McGregor, Simon and Baltieri, Manuel and Buckley, Christopher L.},
eprint = {1503.04187},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/McGregor{\_}2015{\_}MinimalActInfAgent.pdf:pdf},
pages = {1--19},
title = {{A Minimal Active Inference Agent}},
url = {http://arxiv.org/abs/1503.04187},
year = {2015}
}
@article{Kruglanski2020,
abstract = {People often seek new information and eagerly update their beliefs. Other times they avoid information or resist revising their beliefs. What explains those different reactions? Answers to this question often frame information processing as a competition between cognition and motivation. Here, we dissolve this dichotomy by bringing together two theoretical frameworks: epistemic motivation and active inference. Despite evolving from different intellectual traditions, both frameworks attest to the indispensability of motivational considerations to the epistemic process. The imperatives that guide model construction under the epistemic motivation framework can be mapped onto key constructs in active inference. Drawing these connections offers a way of articulating social psychological constructs in terms of Bayesian computations and provides a generative testing ground for future work.},
author = {Kruglanski, Arie W. and Jasko, Katarzyna and Friston, Karl},
doi = {10.1016/j.tics.2020.03.004},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Kruglanski{\_}2020{\_}WishfulThinking.pdf:pdf},
issn = {1879307X},
journal = {Trends in Cognitive Sciences},
keywords = {active inference,epistemic motivation,surprise},
number = {6},
pages = {413--424},
pmid = {32284177},
publisher = {Elsevier Ltd},
title = {{All Thinking is ‘Wishful' Thinking}},
url = {https://doi.org/10.1016/j.tics.2020.03.004},
volume = {24},
year = {2020}
}
@article{Friston2006,
abstract = {By formulating Helmholtz's ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses. In this paper, we show these perceptual processes are just one aspect of emergent behaviours of systems that conform to a free energy principle. The free energy considered here measures the difference between the probability distribution of environmental quantities that act on the system and an arbitrary distribution encoded by its configuration. The system can minimise free energy by changing its configuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment assumes that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at the models entailed by the brain and how minimisation of its free energy can explain its dynamics and structure. {\textcopyright} 2006.},
author = {Friston, Karl and Kilner, James and Harrison, Lee},
doi = {10.1016/j.jphysparis.2006.10.001},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2006{\_}FEPforTheBrain.pdf:pdf},
issn = {09284257},
journal = {Journal of Physiology Paris},
keywords = {Action,Attention,Free energy,Hierarchical,Inference,Learning,Perception,Selection,Variational Bayes},
number = {1-3},
pages = {70--87},
pmid = {17097864},
title = {{A free energy principle for the brain}},
volume = {100},
year = {2006}
}
@article{Millidge2019,
abstract = {Active Inference is a theory of action arising from neuroscience which casts action and planning as a bayesian inference problem to be solved by minimizing a single quantity – the variational free energy. Active Inference promises a unifying account of action and perception coupled with a biologically plausible process theory. Despite these potential advantages, current implementations of Active Inference can only handle small, discrete policy and state-spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm which approximates key densities using deep neural networks as flexible function approximators, which enables Active Inference to scale to significantly larger and more complex tasks. We demonstrate our approach on a suite of OpenAIGym benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm shows similarities with maximum entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1907.03876},
author = {Millidge, Beren},
eprint = {1907.03876},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/millidge2020.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Active Inference,Actor-Critic,Neural Networks,OpenAI Gym,Policy Gradients,Predictive Processing,Reinforcement Learning},
pages = {1--15},
title = {{Deep Active Inference As Variational Policy Gradients}},
volume = {96},
year = {2019}
}
@article{Karl2012,
abstract = {This paper describes a free energy principle that tries to explain the ability of biological systems to resist a natural tendency to disorder. It appeals to circular causality of the sort found in synergetic formulations of self-organization (e.g., the slaving principle) and models of coupled dynamical systems, using nonlinear Fokker Planck equations. Here, circular causality is induced by separating the states of a random dynamical system into external and internal states, where external states are subject to random fluctuations and internal states are not. This reduces the problem to finding some (deterministic) dynamics of the internal states that ensure the system visits a limited number of external states; in other words, the measure of its (random) attracting set, or the Shannon entropy of the external states is small. We motivate a solution using a principle of least action based on variational free energy (from statistical physics) and establish the conditions under which it is formally equivalent to the information bottleneck method. This approach has proved useful in understanding the functional architecture of the brain. The generality of variational free energy minimisation and corresponding information theoretic formulations may speak to interesting applications beyond the neurosciences; e.g., in molecular or evolutionary biology. {\textcopyright} 2012 by the authors.},
author = {Friston, Karl},
doi = {10.3390/e14112100},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2012{\_}FEP{\_}Biological{\_}Systems.pdf:pdf},
issn = {10994300},
journal = {Entropy},
keywords = {Bayesian,Ergodicity,Free energy,Random dynamical system,Self-organization,Surprise},
number = {11},
pages = {2100--2121},
title = {{A free energy principle for biological systems}},
volume = {14},
year = {2012}
}
@article{Allen2018,
abstract = {Predictive processing (PP) approaches to the mind are increasingly popular in the cognitive sciences. This surge of interest is accompanied by a proliferation of philosophical arguments, which seek to either extend or oppose various aspects of the emerging framework. In particular, the question of how to position predictive processing with respect to enactive and embodied cognition has become a topic of intense debate. While these arguments are certainly of valuable scientific and philosophical merit, they risk underestimating the variety of approaches gathered under the predictive label. Here, we first present a basic review of neuroscientific, cognitive, and philosophical approaches to PP, to illustrate how these range from solidly cognitivist applications—with a firm commitment to modular, internalistic mental representation—to more moderate views emphasizing the importance of ‘body-representations', and finally to those which fit comfortably with radically enactive, embodied, and dynamic theories of mind. Any nascent predictive processing theory (e.g., of attention or consciousness) must take into account this continuum of views, and associated theoretical commitments. As a final point, we illustrate how the Free Energy Principle (FEP) attempts to dissolve tension between internalist and externalist accounts of cognition, by providing a formal synthetic account of how internal ‘representations' arise from autopoietic self-organization. The FEP thus furnishes empirically productive process theories (e.g., predictive processing) by which to guide discovery through the formal modelling of the embodied mind.},
author = {Allen, Micah and Friston, Karl J},
doi = {10.1007/s11229-016-1288-5},
file = {:home/esther/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen, Friston - 2018 - From cognitivism to autopoiesis towards a computational framework for the embodied mind.pdf:pdf},
issn = {15730964},
journal = {Synthese},
keywords = {Active inference,Computationalism,Connectionism,Embodied cognition,Enactivism,Interoception,Predictive processing},
number = {6},
pages = {2459--2482},
title = {{From cognitivism to autopoiesis: towards a computational framework for the embodied mind}},
url = {https://doi.org/10.1007/s11229-016-1288-5},
volume = {195},
year = {2018}
}
@article{Friston2008,
abstract = {This paper describes a general model that subsumes many parametric models for continuous data. The model comprises hidden layers of state-space or dynamic causal models, arranged so that the output of one provides input to another. The ensuing hierarchy furnishes a model for many types of data, of arbitrary complexity. Special cases range from the general linear model for static data to generalised convolution models, with system noise, for nonlinear time-series analysis. Crucially, all of these models can be inverted using exactly the same scheme, namely, dynamic expectation maximization. This means that a single model and optimisation scheme can be used to invert a wide range of models. We present the model and a brief review of its inversion to disclose the relationships among, apparently, diverse generative models of empirical data. We then show that this inversion can be formulated as a simple neural network and may provide a useful metaphor for inference and learning in the brain. {\textcopyright} 2008 Karl Friston.},
author = {Friston, Karl},
doi = {10.1371/journal.pcbi.1000211},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/KFriston{\_}2008{\_}HierarchicalModel.PDF:PDF},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {11},
pmid = {18989391},
title = {{Hierarchical models in the brain}},
volume = {4},
year = {2008}
}
@article{Millidge2020,
abstract = {Active Inference is a theory arising from theoretical neuroscience which casts action and planning as Bayesian inference problems to be solved by minimizing a single quantity — the variational free energy. The theory promises a unifying account of action and perception coupled with a biologically plausible process theory. However, despite these potential advantages, current implementations of Active Inference can only handle small policy and state–spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm that approximates key densities using deep neural networks as flexible function approximators, which enables our approach to scale to significantly larger and more complex tasks than any before attempted in the literature. We demonstrate our method on a suite of OpenAIGym benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm evokes similarities with maximum-entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning.},
author = {Millidge, Beren},
doi = {10.1016/j.jmp.2020.102348},
file = {:home/esther/Desktop/bachelor/papers/potentially nteresting/Millidge{\_}2020{\_}DeepActInf.pdf:pdf},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
keywords = {Active inference,Neural networks,Policy gradients,Predictive processing,Reinforcement learning},
pages = {102348},
publisher = {Elsevier Inc.},
title = {{Deep active inference as variational policy gradients}},
url = {https://doi.org/10.1016/j.jmp.2020.102348},
volume = {96},
year = {2020}
}
